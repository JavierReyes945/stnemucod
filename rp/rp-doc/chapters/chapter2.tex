%%%
%  File: chapter2.tex
%  Project: rp-doc
%  Author: Javier Reyes (javier.reyes.g@gmail.com)
%  Created on: 09.09.2018
%  
%  Modified By: Javier Reyes
%  Last Modified: 10.09.2018
%  
%  MIT License
%  
%  Copyright (c) 2018 Javier Reyes
%  
%  Permission is hereby granted, free of charge, to any person obtaining a copy of
%  this software and associated documentation files (the "Software"), to deal in
%  the Software without restriction, including without limitation the rights to
%  use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
%  of the Software, and to permit persons to whom the Software is furnished to do
%  so, subject to the following conditions:
%  
%  The above copyright notice and this permission notice shall be included in all
%  copies or substantial portions of the Software.
%  
%  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
%  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
%  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
%  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
%  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
%  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
%  SOFTWARE.
%%%

\chapter{Hardware Platform Design}

The workflow for the Zynq-7000 architecture starts with the hardware specification for both PS and
PL technologies. Xilinx provide a complete suite of programs and tools for the entire design cycle
of the embedded solution, either in a standalone platform or in an embedded OS.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{embedded-flow.png}
	\caption{Embedded Design Process Flow, from \cite{UG1043}.} \label{fig:embedded-flow}
\end{figure}%

The workflow is split into different tools provided by Xilinx. The hardware specific tasks will be
covered in section \ref{hardware-design}. The software component will be covered in chapters
\ref{embedded-linux} and \ref{software-application}.

\section{Hardware Design} \label{hardware-design}

For the definition, configuration and flashing of the FPGA fabric, the Vivado Design Suite includes
the necessary tools. The distribution of tasks and their respective tool scenario is shown in figure
\ref{fig:hardware-tasks-tools}.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{hardware-tasks-tools.png}
	\caption{Hardware design tasks and tools scenario, from \cite{UG1043}.}
	\label{fig:hardware-tasks-tools}
\end{figure}%

The typical Hardware/Software Co-Design present in the tools allows a continuous verification and
validation of the design. For this project, the process include a third element for building a
custom Linux OS, which will be covered in chapter \ref{embedded-linux}. There are several approaches
to create a hardware definition for the Zynqberry board in the Vivado Desgin Suite, either a
GUI-based interaction, or a TCL console.

\subsection{Vivado GUI}

The process for a Zynq-7000 device can be easily done in the Vivado GUI, under Windows or Linux
operative systems. The general procedure can be listed as follows:

\begin{enumerate}
	\item Start the Vivado IDE.
	\item Create New Project.
	\begin{enumerate}
		\item Define Project name and location.
		\item Select RTL project type.
		\item If necessary, add any source files (HDL or constraints).
		\item Select the device as ZYNQ XC7Z010-CLG225-1.
	\end{enumerate}
	\item Create New Block Design.
	\item Add the IP Core for the ZYNQ7 Processing System.
	\item Configure the desired characteristics of the PS and PL.
	\item If necessary, add additional IP Cores, or create own IP Core with HLS (See Appendix
	\ref{appen2}).
	\item Run the Block Automation or Connection Automation if required.
	\item Validate the Block Design.
	\item If necessary, assign the required constraints.
	\item Run the Synthesis, Implementation and Generate Bitstream.
	\item Export the Hardware Platform (including Bitstream).
\end{enumerate}

The general process can contain small variances depending on the specific design. From this point,
the software design can be started, by using the exported hardware definition into the SDK. This
part is expanded in chapter \ref{software-application}.

\subsection{TCL Console}

The entire process made in Vivado GUI can be performed in a TCL console by using text-based scripts.
This makes some environments more adequate for maintainability and expandability, and even
facilitates the use of VCS tools by having the hardware definition described in a text file.

The Vivado core has included a TCL engine, which has been used as an industry standar choice for
scripting and automating software tasks. For a project created using the GUI, actions are displayed
as TCL commands in the TCL console, and the commands are saved in a file \texttt{vivado.jou} and
together with the returned messages in the file \texttt{vivado.log}. A typical project creation
script is shown in snippet \ref{tcl-script}.

\begin{lstlisting}[language=tcl, basicstyle=\scriptsize\ttfamily, tabsize=2,
	commentstyle=\color{darkgray}, keywordstyle=\color{blue}, backgroundcolor=\color{lightgray},
	morekeywords={create_project, add_files, import_files, set_property, update_compile_order,
	launch_runs, wait_on_run, open_run, report_timming_summary, report_power}, breaklines=true,
	numbers=left, float=htb,
	caption={[TCL project creation example]TCL project creation example, from \cite{UG895}},
	label={tcl-script}]
	# Typical usage: vivado -mode tcl -source run_bft_project.tcl
	# Create the project and directory structure
	create_project -force project_bft_batch ./project_bft_batch -part xc7z010-clg225-1
	#
	# Add various sources to the project
	add_files {./Sources/hdl/FifoBuffer.v ./Sources/hdl/async_fifo.v \
	./Sources/hdl/bft.vhdl}
	add_files -fileset sim_1 ./Sources/hdl/bft_tb.v
	add_files ./Sources/hdl/bftLib/
	add_files -fileset constrs_1 ./Sources/bft_full.xdc
	#
	# Now import/copy the files into the project
	import_files -force
	#
	# Set VHDL library property on some files
	set_property library bftLib [get_files {*round_*.vhdl core_transform.vhdl \
	bft_package.vhdl}]
	#
	# Update to set top and file compile order
	update_compile_order -fileset sources_1
	update_compile_order -fileset sim_1
	#
	# Launch Synthesis
	launch_runs synth_1
	wait_on_run synth_1
	open_run synth_1 -name netlist_1
	#
	# Generate a timing and power reports and write to disk
	# Can create custom reports as required
	report_timing_summary -delay_type max -report_unconstrained -check_timing_verbose \
	-max_paths 10 -input_pins -file syn_timing.rpt
	report_power -file syn_power.rpt
	#
	# Launch Implementation
	launch_runs impl_1 -to_step write_bitstream
	wait_on_run impl_1
	#
	# Generate a timing and power reports and write to disk
	# comment out the open_run for batch mode
	open_run impl_1
	report_timing_summary -delay_type min_max -report_unconstrained \
	-check_timing_verbose -max_paths 10 -input_pins -file imp_timing.rpt
	report_power -file imp_power.rpt
	#
	# Can open the graphical environment if visualization desired
	# comment out the for batch mode
	#start_gui
\end{lstlisting}

\section{Block Design} \label{block-design}

The design of the hardware portion of the system can be considered in itself a project, and the
complexity of it would make this work out of focus. Therefore, an overview of the tool capabilities
and procedures related is presented.

The expected designed intended to use the AXI DMA IP Core module provided by Xilinx, which allows to
transfer data from the system memory into any AXI4-Stream-based IP Core.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{zynq-memory-mapped-axi.png}
	\caption{Described configuration for data transfer between PS and PL, from \cite{UG1046}.}
	\label{fig:zynq-memory-mapped-axi}
\end{figure}

The AXI DMA shall be connected to the processor as shown in figure \ref{fig:fpga-dma-diag}. The
module is controlled by the processor by the General Purpose AXI GP0 port through AXI-Lite protocol.
The data itself shall be transfered through the High Performance AXI HP0 through the
MemoryMap2Stream MM2S and S2MM ports in the DMA.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{fpga-dma-diag.png}
	\caption{PL design for DMA usage in Zynq.}
	\label{fig:fpga-dma-diag}
\end{figure}

The final application was still not able to run, due to problems with the address configuration for
the mapping in Linux embedded, as the documentation and examples are contemplated for standalone
implementations, where the memory space can be directly controlled by the user application.

In our case, the OS will need to define a block segment out of the kernel space in order to be able
to read/write to that section by passing the address directly to the DMA control register. This
modification in the predefined Petalinux project has proven to be of higer complexity, and still not
working as desired.

\subsection{Custom IP Core} \label{custom-ip-core}

Once the hardware design has been able to move data back and forth between the PS and PL logic, a
user-defined IP block nneds to be included, which shall provide the main parallel execution in the
FPGA section of the Zynq. As explained in \ref{block-design}, the functionality of this design is
still Work In Progress, as the challenge of manage memory sections in a Linux OS environment is
quite complex. We present the workflow for this task as documentation and support for future work.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{custom-ip-workflow.png}
	\caption{Custom IP Package workflow, from \cite{UG1118}.}
	\label{fig:custom-ip-workflow}
\end{figure}

The User-defined IP Core can be packed with the IP Packager in Vivado. The methodology for packaging
sources into a functional IP block are detailed in \cite{UG1118}. The way Vivado works with a custom
IP inside the main project can be quite complex and not well documented, so it is recommended (by
the author of this work) that the design is first created, tested and packed in a standalone
project, and then the sources used in the main project to pack the final Custom IP block.

The general idea is that an IP package contains a block design (which is an internal representation
format of a logic hardware design). For the custom IP to be used from the PS, the AXI protocol needs
to be used for the access to the registers. This can be selected in the custom IP wizard, which
allows to select to pack a design from defined source files, either from a specific directory or
from the current project directory, or a pack of a complete AXI4 peripheral (which includes IP
logic, drivers, testbenches and debug options). The workflow gets highly complex when the AXI
potocol comes into use, which is one of the reasons of the incomplete result of this work.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{ip-package-options.png}
	\caption{Custom IP Package init options, from \cite{UG1118}.}
	\label{fig:ip-package-options}
\end{figure}

Once the IP has been packed, it can be added to the main Block Design, and included into the PL
bitstream for the Zynq device. The objective result conclusions from this experience are detailed in
chapter \ref{conclusions}.
